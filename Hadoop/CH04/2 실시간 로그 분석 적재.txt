
<실시간 로그/분석 적재>
- 스마트카 운전자의 실시간 운행 정보를 분석한 후 적재
- 작지만 대량으로 발생하는 메세지성 데이터를 실시간으로 분석(집계, 분류, 관계 등) 처리 -> 해당 결과를 인메모리에 저장해 주변 시스템과 빠르게 공유
- 하둡을 직접 이용하지는 않음 -> 영구 저장할 필요가 없기 때문에 !!
- 특정 크기로 모았다가 한꺼번에 적재하거나 대규모 트랜잭션 데이터를 처리하는 데 최적화된 칼럼 지향형 NoSQL 데이터베이스를 주로 사용

< HBase> :  하둡의 HDFS를 기반으로 설치 및 구성
- NoSQL 데이터베이스들은 데이터를 키/값(Key/Value) 구조로 단순화하고, 컬럼 또는 도큐먼트 형식의 제약사항이 적은 스키마 모델로 만들어 고성능 쓰기/읽기가 가능
- HBase는 하둡 기반의 컬럼 지향(Column-Oriented) NoSQL 데이터베이스로서 스키마 변경이 자유롭고, 리전이라는 수십~수백 대의 분산 서버로 샤딩과 복제 등의 기능을 지원해 성능과 안정성을 보장
=> 컬럼 형태로 데이터를 주고받음
- MemStore : 휘발성이 있는, 데이터를 인메모리에 저장 및 관리하는 데이터 캐시 영역
- HFile : 데이터를 스토리지에 저장 및 관리하는 영구 저장영역

클라이언트가 데이터를 저장하기 전에 주키퍼를 통해 해당 HTable, HRegin의 위치 알아냄
    -> 클라이언트가 직접 HRegionServer로 연결되어서 MemStore에 저장
        -> HRegion의 상황에 따라 최적의 파일로 재구성 작업 진행됨
        -> 데이터가 HRegin에 없으면 하둡의 DataNode로부터도 찾아옴


<레디스> : 분산 캐시 시스템 & NoSQL 데이터베이스처럼 대규모 데이터 관리 능력도 갖춘 IMDG(In-Memory Data Grid) 소프트웨어
- 인메모리 데이터를 영구적으로 저장할 수 있는 스냇샵 기능을 제공
- 데이터의 유실에 대비해 AOF(Append Only File) 기능으로 정합성을 보장
(Master(쓰기 노드)-Slave(읽기 노드) 구조 -> Master에 쓰여진 데이터는 복제를 통해 Slave 노드로 복제되면서 데이터 정합성을 유지)
    => 마스터 서버 장애 발생을 대비해서 Sentinel 컴포넌트(노드 모니터링/제어)가 추가됨
- 분석한 결과를 빠르게 저장하면서 주변 시스템과 공유하기 위한 저장소로 레디스를 활용

예시 ) Storm에서 두 개의 경로로 분리 - HBase / 레디스
        -> HBase에는 운전자의 모든 상태 정보를 저장
        -> 레디스에는 운전자의 특정 패턴을 감지한 이벤트 결과(과속한 운전자 정보)만 저장


<스톰> : 스피드 데이터를 실시간으로 인메모리 상에서 병렬 처리하기 위한 소프트웨어
- 분산 데이터를 통제하기 위한 강력한 기능(분리, 정제, 통합, 집계 등)과 아키텍처도 제공

예시)  카프카의 Spout를 통해 유입되는 모든 운전자의 운행 정보 데이터는 두 개의 Bolt(HBase Bolt, Redis Bolt)로 나눠져서 처리됨
        ->  HBase Bolt는 모든 운행 정보를 정제 없이 HBase 서버에 곧바로 적재
        -> 레디스 Bolt는 에스퍼라는 룰 엔진이 감지한 이상 운행 패턴의 정보만 레디스 서버에 적재

* 실시간 분산 처리 유형
    완전 실시간 방식 : 데이터 발생과 동시에 처리 << 스톰!!!
    마이크로 배치 방식 : 발생한 데이터를 적재한 후 빠르게 배치를 실행


에스퍼 : 실시간 스트리밍 데이터의 복잡한 이벤트 처리가 필요할 때 사용하는 룰 엔진
- 실시간으로 발생하는 데이터 간의 관계를 복합적으로 판단 및 처리하는 CEP(Complex Event Processing) 기능 제공
- 분산된 응용 서버에 에스퍼 엔진을 설치하고, 에스퍼 엔진들이 동일한 EPL 룰을 동적으로 일괄 로딩하기 위해 EPL 공유 저장소가 이용됨
예시 ) EPL은 30초 동안의 평균 시속을 체크해서 80km/h를 초과하는 운전자 이벤트 정보를 실시간으로 감지할 수 있도록 룰을 정의
        ->  해당 이벤트 데이터는 감지 즉시 레디스에 적재되어 과속한 차량정보만 관리할 수 있음



< 실시간 적재 요구사항 구체화 분석 & 해결 방안 >

1. 1초 간격으로 발생하는 100명의 운행 정보(운행 정보 1건: 약 4KB)는 손실 없이 적재해야 한다.
    => 카프카와 스톰을 이용해 수집한 데이터에 대해 분산 처리 및 무결성을 보장하며, 분산 처리가 완료된 데이터는 HBase에 적재

2. 적재한 운행 정보를 대상으로 조건 검색이 가능해야하며, 필요 시 수정도 가능해야 한다.
    => HBase의 테이블에 적재된 데이터는 스캔 조건으로 검색하며, 저장 (Put) 기능을 이용해 기적재한 데이터에 대해 칼럼 기반으로 수정

3. 운전자의 운행 정보 중 30초를 기준으로 평균 속도가 80Km/h를 초과한 정보는 분리 적재한다.
    => 에스퍼의 EPL에서 사용자별로 운행 정보를 그루핑하고, 30초의 윈도우 타임(Window Time) 조건으로 평균 시속 집계 및 임계치별 이벤트를 정의

4. 과속한 차량을 분리 적재하기 위한 조건은 별도의 룰로 정의하고 쉽게 수정할 수 있어야 한다.
    => 과속 기준을 80Km/h에서 100Km/h로 변경해야 할 경우 EPL의 평균 속도를 체크하는 조건값만 수정

5. 분리 적재한 데이터는 외부 애플리케이션이 빠르게 접근하고 조회할 수 있게 해야 한다.
    => 실시간 이벤트로 감지된 데이터는 인메모리 기반 저장소인 레디스에 적재해서 외부 애플리케이션에서 빠르게 조회

6. 레디스에 적재한 데이터는 저장소의 공간을 효율적으로 사용하기 위해 1주일이 경과하면 영구적으로 삭제한다.
    => 레디스 클라이언트 라이브러리인 제디스(Jedis) 클라이언트를 이용해 데이터 적재 시 만료(Expire) 시간을 설정해 자동으로 영구 삭제 처리

7. 스톰의 실시간 데이터 처리
- 스톰은 카프카로부터 수신받은 운행 정보 데이터를 분산 처리하고, 최종 목적지 저장소에 적재하는 역할을 수행한다.
- 이때 빠르게 유입되는 데이터로부터 의미 있는 패턴을 발견하기 위해 에스퍼 엔진을 이용한다.
(1) 스톰의 Spout가 카프카의 토픽으로부터 운전자의 실시간 운행 정보를 수신받아 첫 번째 볼트에 전송한다. 
    해당 Bolt에서는 모든 운행 정보를 HBase Bolt로 전송하면서, 
    에스퍼의 EPL에서 정의한 조건에 따라 과속한 차량의 정보를 레디스 Bolt에 전송한다.
(2) HBase에 모든 운전자 운행 정보 적재
    HBase의 테이블에는 “차량번호+발생일시"를 로우키로 해서 8개의 칼럼(발생 일시, 차량 번호, 가속 페달, 브레
    이크 페달, 운전대 회전각, 방향지시등, 주행 속도, 주행 구역)의 구조로 모든 스마트카 운전자의 운행 정보가 적재된다.
(3) 레디스에 과속한 운전자 정보 적재
    레디스에 적재될 때는 현재 날짜를 키로 해서 과속한 차량의 정보를 세트 데이터 구조로 적재한다. 
    적재 영속 시간은 5시간으로 하며, 이후에 만료 처리되어 메모리에서 자동으로 삭제된다.

HBase 테스트 =========================================================================
=> 컬럼 형태로 데이터를 주고받음
http://server02.hadoop.com:16010/ 에서 확인 가능

# hbase shell   >> hbase 접속
> create "smartcar_test_table", "cf"
> put "smartcar_test_table", "row-key1", "cf:model", "Z0001"
> put "smartcar_test_table", "row-key1", "cf:no", "12345"
> get "smartcar_test_table", "row-key1"
    COLUMN                            CELL                                                                                             
    cf:model                         timestamp=1650876658458, value=Z0001                                                             
    cf:no                            timestamp=1650876686161, value=12345                                                             
    1 row(s)
> disable "smartcar_test_table" > 사용안함
> enable "smartcar_test_table"  > 사용
> drop "smartcar_test_table"    > 삭제(disable 후에 명령하기)

Redis 설치 ===========================================================================

# rpm -qa | grep gcc
# yum install -y gcc*   >> no valid mirrors => CentOS 6에서는 개발이 중단 된 상태

<캐시폴더에 미러리스트 복붙>
echo "http://vault.centos.org/6.10/os/x86_64/" > /var/cache/yum/x86_64/6/base/mirrorlist.txt
echo "http://vault.centos.org/6.10/extras/x86_64/" > /var/cache/yum/x86_64/6/extras/mirrorlist.txt
echo "http://vault.centos.org/6.10/updates/x86_64/" > /var/cache/yum/x86_64/6/updates/mirrorlist.txt
echo "http://vault.centos.org/6.10/sclo/x86_64/rh" > /var/cache/yum/x86_64/6/centos-sclo-rh/mirrorlist.txt
echo "http://vault.centos.org/6.10/sclo/x86_64/sclo" > /var/cache/yum/x86_64/6/centos-sclo-sclo/mirrorlist.txt

# yum install gcc* tcl -y       >> gcc*, tcl 설치
# cd /home/pilot-pjt/
# wget http://download.redis.io/releases/redis-5.0.7.tar.gz
# tar -xf redis-5.0.7.tar.gz       >> 압축 풀기 (-xvf : 압축 풀린 파일 보이는 명령어 추가(v))
# cd /home/pilot-pjt/redis-5.0.7/
# make      >> C언어기 때문에 해당 명령어로 실행파일화 !!
# make install  >> src폴더에 저장된 실행파일로 설치/실행을 함 !
# cd /home/pilot-pjt/redis-5.0.7/utils  >> ls로 목록 보면 install_server.sh 실행시켜야함
# ./install_server.sh   >> 전부 다 엔터로 승인(기본값으로 실행)
        path[]에서 /usr/local/bin/redis-server 입력 후 엔터 !!

# vim /var/log/redis_6379.log   >> 로그파일 보기 (:q로 exit)
# service redis_6379 status     >> running중인지 확인
# vim /etc/redis/6379.conf      >> 설정파일 수정(/ << 검색기능)
    >> /bind 127.0.0.1  >> 주석처리
    >> /protected-mode  >> no로 변경(password 입력 사용 안함)
# vim ~/.bash_profile   
    >> PATH=$PATH:$HOME/bin:/usr/local/bin 으로 수정
    >> source ~/.bash_profile

# service redis_6379 restart
# /usr/local/bin/redis-cli
테스트해보기
> set key:1 Hello!Bigdata
> get key:1
> del key:1

스톰 설치 ============================================================================

# cd /home/pilot-pjt/
# wget http://archive.apache.org/dist/storm/apache-storm-1.2.3/apache-storm-1.2.3.tar.gz
# tar -xvf apache-storm-1.2.3.tar.gz 
# ln -s apache-storm-1.2.3 storm
# cd /home/pilot-pjt/storm/conf/
# vim storm.yaml >> 스톰 설정파일 - 아래 내용 아무데나 추가 
    storm.zookeeper.servers:
    - "server02.hadoop.com"
    storm.local.dir: "/home/pilot-pjt/storm/data"
    nimbus.seeds: ["server02.hadoop.com"]
    supervisor.slots.ports: 
    - 6700
    ui.port: 8088                   >> ui 접속포트
# cd /home/pilot-pjt/storm/log4j2/
# vim cluster.xml        >> 75~90번째 줄 (:set nu 로 줄번호 조회 가능) level="error"로 수정
# vim worker.xml         >> 75~90 동일하게 변경
# vim /root/.bash_profile
    PATH=$PATH:$HOME/bin:/usr/local/bin
    PATH=$PATH:/home/pilot-pjt/storm/bin >> 추가
# source /root/.bash_profile
# echo $PATH        >> 추가된 경로 확인 가능

CH05의 nimbus, supervisor, ui파일들을 파일질라로 /etc/rc.d/init.d 에 추가 
>> 전송 후 세 개의 파일 우클릭 - 권한 - 755
# mkdir /var/{log,run}/storm >> 로그, 동작 폴더 생성
# ls -l /var/{log,run}/storm >> 두 디렉터리 동시 조회 가능 !!

# chmod 777 /etc/init.d/storm-*
# /etc/rc.d/init.d/storm-ui start
# /etc/rc.d/init.d/storm-supervisor start
# /etc/rc.d/init.d/storm-nimbus start
=> http://server02.hadoop.com:8088/ 에서 조회 가능


# hbase org.apache.hadoop.hbase.util.RegionSplitter DriverCarInfo HexStringSplit -c 2 -f cf1
    >> region을 두 개 만들기 -> client.HBaseAdmin: Operation: CREATE, Table Name: default:DriverCarInfo, procId: 10 completed 메세지 뜨면 성공
* 애플리케이션 구현파일의 jar파일 두 개를 /home/pilot-pjt/working 폴더로 전송하기(파일질라)
# cd /home/pilot-pjt/working
# storm jar bigdata.smartcar.storm-1.0.jar com.wikibook.bigdata.smartcar.storm.SmartCarDriverTopology DriverCarInfo
        >> DriverCarInfo라는 이름으로 스톰 생성
# storm kill "DriverCarInfo"

데이터 흐름 : Flume -> Kafka -> Storm -> HBase

# java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20220426 10 &
# tail -f /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log >> 수집되고있는 데이터 확인
# hbase shell
> count "DriverCarInfo"     >> 1000단위의 행, 총 행 개수 출력됨
> scan 'DriverCarInfo'      >> 모든 행 출력, 각 행의 정보값이 나옴
> scan 'DriverCarInfo', {STARTROW=>'00016062402202-O0010',LIMIT=>2}  해당 행 값부터 2개의 행 표시
> scan 'DriverCarInfo', {COLUMNS=>['cf1:car_number','cf1:area_number'],FILTER=>"RowFilter(=,'regexstring:62402202') AND SingleColumnValueFilter('cf1','area_number',=,'regexstring:F06')"}


레디스 구동 확인 =========================================================
# redis-cli
> SMEMBERS 20220426             >> 과속으로 필터링 된 정보 출력

# cd /home/pilot-pjt/working
# java -cp bigdata.smartcar.redis-1.0.jar com.wikibook.bigdata.smartcar.redis.OverSpeedCarInfo 20220426     >> 과속한 차량 찾기

* 지금까지 테스트한 로그 다 죽이기
# ps -ef | grep smartcar.log
# kill -9 1093 8037
# service storm-nimbus stop
# service storm-supervisor stop
# service storm-ui stop
# service redis_6379 stop