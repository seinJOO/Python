<수집.pdf, 예제 3.4 대로 플럼 구성파일 세팅하기>
플럼 2 유형 - 하나의 플럼 에이전트 안에서 인터셉터를 통해 데이터를 전송함
+ 싱글 브로커 싱글 노드 (주키퍼)
소스 -> 인터셉터 -> 채널 순으로 데이터가 수집됨


- 수집 아키텍처
스마트카 -> 플럼 spooldir source -> memory channel -> logger sink -> 플럼 log파일 (Stdout)
드라이버인포 -> 플럼 -> exectail source -> memory channel -> kafka sink -> kafka topic

<초기 변수 설정>
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource DriverCarInfo_TailSource
SmartCar_Agent.channels = SmartCarInfo_Channel DriverCarInfo_Channel            >> 채널 선언
SmartCar_Agent.sinks    = SmartCarInfo_LoggerSink  DriverCarInfo_KafkaSink      >> 저장소 선언



SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000

Source Interceptor >> 실시간 정보 수집
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = filterInterceptor    >> 정보 수집 시 filter를 거칠 수 있도록 filterInterceptor 선언
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\\d{14}  >> 정규표현식 = 14자리 날짜 형식만
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false   >> false면 정규표현식 대상만 수집, True면 제외 대상만 수집

SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory          >> (저장소의) 자원에 대한 정보 선언 - SmartCarInfo로부터 오는 데이터에 대한 저장정보
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000


SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.type = logger          >> 저장소 선언

SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel >> 해당 Sorce, sink들을 channel로 전달하도록 설정
SmartCar_Agent.sinks.SmartCarInfo_LoggerSink.channel = SmartCarInfo_Channel


SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec     >> 디렉터리 안에 있는 정보 수집
SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log >> 로그에 저장되는 실시간 정보를 수집
SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000



SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors = filterInterceptor2

SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\\d{14}
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false

>> 수집된 데이터를 카프카에 전송 - 카프카는 프로그램에 의해 데이터를 받아서 처리함
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic     >> 카프카에 생성한 토픽과 이름이 정확히 일치해야 함 !!!
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server02.hadoop.com:9092      >> 카프카의 서비스 인스턴스 - topic이 생성되는 물리적 서버
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000


SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
SmartCar_Agent.channels.DriverCarInfo_Channel.capacity= 100000
SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000


SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel

================================================================================
<카프카 실습>
토픽 - 브로커에서 데이터의 발행/소비 처리를 위한 저장소
카프카는 실시간 데이터를 처리하기 위해 만들어진 프로그램에
아주 빠르게 발생하는 데이터를 채널에 전달하기 전 중간에서 안정적인 버퍼링 처리를 함

1) SmartCar-Topic 생성
$ kafka-topics --create --zookeeper server02.hadoop.com:2181 --replication-factor 1 --partitions 1 --topic SmartCar-Topic
replication-factor : 다중브로커 사용 시 복제할 factor 개수 / partitions : 해당 토픽에 데이터를 분리 저장할 파티션 개수

2) SmartCar-Topic 삭제 시
$ kafka-topics --delete --zookeeper server02.hadoop.com:2181 --topic SmartCar-Topic

3) 생성된 카프카의 토픽에 Producer로 접속
kafka-console-producer --broker-list server02.hadoop.com:9092 -topic SmartCar-Topic

4) 새 탭 열어서 consumer 생성
kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning
    => 카프카 토픽에 Producer로 접속해서 데이터를 입력했을 때 consumer에 그대로 출력됨 -> consumer가 저장소 역할을 해줌 !!
5) 탭 하나 더 열어서 두번째 consumer 생성
kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0 --from-beginning
    => Producer에서 데이터를 입력하면 두 consumer 모두 데이터가 입력되는 대로 출력함~!

6) Producer에서 스마트카 & 드라이버인포 로거 발생기 가동하기
cd /home/pilot-pjt/working
java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20220425 3 &
            >> & : 로그는 포어그라운드가 아닌 백그라운드에서 기록되기 때문에 백그라운드로 접속해줌

ps -ef |grep [pid] >> ~~~ 정보 확인 (pid=9304)
java -cp bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20220425 3 &

7) 만들어지고 있는 로거 조회하기
cd driver-realtime-log
tail -f SmartCarDriverInfo.log      >> 저장되는 로그파일 데이터 조회
ll      >> working폴더로 돌아가서 입력 시 현재 파일 리스트 조회 가능
cd SmartCar/
ls          >> 스마트카 폴더에 저장된 스마트카 로거 리스트 확인
cat SmartCarStatusInfo_20220425.txt     >> 리스트 중 하나 데이터 조회해보기

8) 파일 옮기기
cd SmartCar/
mv ./SmartCarStatusInfo_20220425.txt /home/pilot-pjt/working/car-batch-log/
    >> 플럼 구성에서 SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
    >> 요러케 설정해놨기 때문에 설정한 폴더로 옮기기 !
(cp ./SmartCar/SmartCarStatusInfo_20220425.txt ./car-batch-log/)
(cp : 파일 복사 / mv : 파일 이동 및 원본 삭제)

==수업순서대로필기==

9) 두 consumer에서 데이터 수집중인 것 중단 !

10) 플럼 재시작

11) 지금 현재 수집되고있는 정보만! 조회할 거기 때문에 --from-beginning을 삭제하고 다시 consumer 생성
kafka-console-consumer --bootstrap-server server02.hadoop.com:9092 --topic SmartCar-Topic --partition 0

12) 플럼의 server02에 대한 실시간 로그 조회 -> 다른 탭에서 파일 옮기기 -> 로그에서 실시간으로 입력되고있는 데이터 확인 가능
tail -f /var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log
=> 로그를 켜 놓은 상황에서 다른 탭에서 데이터를 입력하면 로그에 입력되는 데이터들이 그대로 뜸!!! 확인하기

13) 현재 동작중인 로거발생기 찾기
ps -ef | grep DriverLogMain / ps -ef | grep CarLogMain
14) 로거발생기 끄기
kill -9 [pid]
