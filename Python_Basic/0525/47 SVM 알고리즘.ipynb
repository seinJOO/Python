{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 교재 -> 비밀번호 Bigdata!\n",
    "'''\n",
    "어느 정도 규모가 있는 샘플 데이터를 입력으로 넣어 분석 \n",
    "-> 데이터에서 일정한 규칙을 찾아냄\n",
    "-> 찾아낸 규칙을 기반으로 다른 데이터를 분류하거나 미래를 예측\n",
    "'''\n",
    "\n",
    "# 특징 추출 : 데이터가 어떤 특징을 가지고 있는지 찾고 벡터로 만드는 변환 처리\n",
    "#            어떤 특징을 추출할 지는 프로그래머가 결정!\n",
    "\n",
    "# 회귀 분석(regression analysis) : Y가 연속된 값일 때 Y = f(x)와 같은 모델로 나타내는 것\n",
    "#                                선형 회귀(가장 기본적 모델) : Y = aX + b\n",
    "\n",
    "# 지도학습 (Supervised learning) : 데이터와 함께 답을 입력하고 다른 데이터의 답을 예측\n",
    "# 비지도학습 (Unsupervised learning) : 데이터는 입력하지만 답은 입력하지 않고, 다른 데이터의 규칙성을 찾음 - 최종적으로 내야하는 답이 정해져 있지 않다\n",
    "# 강화학습 (Reinforcement learning) : 현재 상태를 관찰해서 어떻게 대응해야 할지와 관련된 문제를 다룸 (최선의 행동을 스스로 테스트하며 학습)\n",
    "#                                    부분적으로 답을 입력하고, 데이터를 기반으로 최적의 답을 찾아냄\n",
    "\n",
    "### 데이터 수집 -> 가공 -> 학습 (방법 선택 -> 매개변수 조정 -> 모델 학습) -> 모델 평가     : 정밀도가 떨어지면 매개변수/알고리즘 재조정\n",
    "# 수집 : 프로그램이 다루기 쉬운 형태로 데이터를 가공할 때 머신러닝에 어떠한 특징을 활용할지, 어떤 형식으로 가공해야할지 생각\n",
    "# 학습 :  어떤 방법(알고리즘)을 사용해 학습을 시킬지 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 알고리즘 장단점\n",
    "# 장점 : 비선형 분리 데이터를 커널트릭을 사용하여 분류 모델링 가능\n",
    "#       고차원 공간에서 원활하게 작동\n",
    "#       텍스트 분류 및 이미지 분류에 효과적\n",
    "\n",
    "# 단점 : 대용량 데이터셋 처리에는 많은 시간이 소요(마진 길이가 줄어듬)\n",
    "#       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[0, 1, 1]\n",
      "[1, 0, 1]\n",
      "[1, 1, 0]\n",
      "예측 결과 : [0 1 1 0]\n",
      "정답률 : 4 / 4 = 1.0\n"
     ]
    }
   ],
   "source": [
    "### scikit-learn : 머신러닝 프레임워크\n",
    "# pip install -U scikit-learn scipy scikit-image\n",
    "\n",
    "### XOR(배타적 논리합) 연산 = 둘 중 하나는 거짓이어야 참 ! (모두 참이거나 모두 거짓일 때는 거짓)\n",
    "\n",
    "### XOR 연산을 학습하는 프로그램\n",
    "from sklearn import svm\n",
    "\n",
    "# XOR의 계산 데이터\n",
    "xor_data = [\n",
    "    # P, Q, Result\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0]\n",
    "]\n",
    "\n",
    "# 학습을 위해 데이터와 레이블 분리\n",
    "data = []\n",
    "label = []\n",
    "for row in xor_data :\n",
    "    print(row)\n",
    "    p = row[0]\n",
    "    q = row[1]\n",
    "    re = row[2]\n",
    "    data.append([p,q])\n",
    "    label.append(re)\n",
    "\n",
    "# 데이터 학습시키기\n",
    "clf = svm.SVC()             # SVM 알고리즘 사용\n",
    "clf.fit(data, label)        # fit() -> 트레이닝 데이터를 넣어서 학습시킴(문제, 답)\n",
    "\n",
    "# 다른 데이터 넣어보기\n",
    "data1 = [\n",
    "    [2,2],\n",
    "    [0,4],\n",
    "    [2,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "# 데이터 예측하기\n",
    "pre = clf.predict(data1)     # predict() -> 데이터를 넣어 예측시킴\n",
    "print('예측 결과 :', pre)\n",
    "\n",
    "# 결과 확인하기\n",
    "ok = 0; total = 0\n",
    "for idx, answer in enumerate(label) :\n",
    "    p = pre[idx]\n",
    "    if p == answer : ok += 1\n",
    "    total += 1\n",
    "    \n",
    "print('정답률 :',ok,'/',total,'=',ok/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import pandas as pd\n",
    "\n",
    "# XOR의 계산 데이터\n",
    "xor_input = [\n",
    "    # P, Q, Result\n",
    "    [0,0,0],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,0]\n",
    "]\n",
    "\n",
    "# 학습을 위해 데이터와 레이블 분리\n",
    "xor_df = pd.DataFrame(xor_input)\n",
    "xor_data = xor_df.iloc[:,0:2]\n",
    "xor_label = xor_df.iloc[:,2]\n",
    "\n",
    "# 데이터 학습 + 예측\n",
    "clf = svm.SVC()            \n",
    "clf.fit(xor_data, xor_label)\n",
    "pre = clf.predict(xor_data)\n",
    "\n",
    "# 결과 확인하기\n",
    "ac_score = metrics.accuracy_score(xor_label, pre)    \n",
    "print('정답률 :',ac_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 붓꽃 데이터 구하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics\n",
    "import random, re\n",
    "\n",
    "# 붖꽃 데이터 읽기\n",
    "csv = []\n",
    "with open('data/iris.csv', 'r', encoding='utf-8') as fp :\n",
    "    for line in fp :\n",
    "        line = line.strip()\n",
    "        cols = line.split(',')\n",
    "        # 문자열 데이터를 숫자로 변환하기, 숫자(소수)가 아니면 그대로\n",
    "        fn = lambda n : float(n) if re.match(r'^[0-9\\.]+$', n) else n\n",
    "        cols = list(map(fn, cols))      \n",
    "        # map() : 리스트의 요소를 지정된 함수로 처리해주는 함수 - list(map(함수, 리스트)) / tuple(map(함수, 튜플)) / list(map(자료형, 리스트))\n",
    "        csv.append(cols)\n",
    "        \n",
    "# 헤더 제거\n",
    "del csv[0]\n",
    "\n",
    "# 데이터 섞기\n",
    "random.shuffle(csv)\n",
    "\n",
    "# 학습 데이터 / 테스트 데이터 분할 (2:1 비율)\n",
    "total_len = len(csv)\n",
    "train_len = int(total_len * 2 / 3)\n",
    "train_data, train_label, test_data, test_label = [], [], [], []\n",
    "\n",
    "for i in range(total_len) :\n",
    "    data = csv[i][0:4]\n",
    "    label = csv[i][4]\n",
    "    if i < train_len :\n",
    "        train_data.append(data)\n",
    "        train_label.append(label)\n",
    "    else :\n",
    "        test_data.append(data)\n",
    "        test_label.append(label)\n",
    "        \n",
    "# 데이터 학습시키고 예측하기\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data, train_label)\n",
    "pre = clf.predict(test_data)\n",
    "\n",
    "# 정답률 구하기\n",
    "ac_score = metrics.accuracy_score(test_label, pre)\n",
    "print('정답률 =', ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.97\n"
     ]
    }
   ],
   "source": [
    "#### iris를 이용한 데이터 처리 - 분할메서드 사용\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 붓꽃 데이터 읽어 들이기 (PANDAS)\n",
    "csv = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# 필요한 열 추출\n",
    "csv_data = csv[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']]\n",
    "csv_label = csv['Name']\n",
    "\n",
    "# 학습 전용 데이터와 테스트 전용 데이터로 나누기 - train_test_split() 메서드 활용 (순서 주의 !!)\n",
    "train_data, test_data, train_label, test_label = train_test_split(csv_data, csv_label)\n",
    "\n",
    "# 데이터 학습시키고 예측하기\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data, train_label)\n",
    "pre = clf.predict(test_data)\n",
    "\n",
    "# 정답률 구하기\n",
    "ac_score = metrics.accuracy_score(test_label, pre)\n",
    "print('정답률 =', round(ac_score,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 내부의 문자 인식 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download : http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "download : http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "download : http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "download : http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## 사이트 주소 : http://yann.lecun.com/exdb/mnist\n",
    "## train-images-idx3-ubyte.gz / train-labels-idx1-ubyte.gz / t10k-images-idx3-ubyte.gz / t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "import urllib.request as req\n",
    "import gzip, os, os.path\n",
    "\n",
    "savepath = 'data/mnist'\n",
    "baseurl = 'http://yann.lecun.com/exdb/mnist'\n",
    "files = [\n",
    "    'train-images-idx3-ubyte.gz',\n",
    "    'train-labels-idx1-ubyte.gz',\n",
    "    't10k-images-idx3-ubyte.gz',\n",
    "    't10k-labels-idx1-ubyte.gz'\n",
    "]\n",
    "\n",
    "# 다운로드\n",
    "if not os.path.exists(savepath) : os.mkdir(savepath)\n",
    "for f in files :\n",
    "    url = baseurl + '/' + f\n",
    "    loc = savepath + '/' + f\n",
    "    print('download :', url)\n",
    "    if not os.path.exists(loc) : req.urlretrieve(url, loc)    # Retrieve a URL into a temporary location on disk.\n",
    "\n",
    "# Gzip 압축 해제\n",
    "for f in files :\n",
    "    gz_file = savepath + '/' + f\n",
    "    raw_file = savepath + '/' + f.replace('.gz','')\n",
    "    with gzip.open(gz_file, 'rb') as fp :\n",
    "        body = fp.read()\n",
    "        with open(raw_file, 'wb') as w :\n",
    "            w.write(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 이미지파일을 필요한 개수만큼만 가져오기\n",
    "\n",
    "import struct\n",
    "\n",
    "def to_csv(name, maxdata) :\n",
    "    # 레이블 파일과 이미지 파일 열기\n",
    "    lbl_f = open(\"data/mnist/\"+name+\"-labels-idx1-ubyte\", \"rb\")\n",
    "    img_f = open(\"data/mnist/\"+name+\"-images-idx3-ubyte\", \"rb\")\n",
    "    csv_f = open(\"data/mnist/\"+name+\".csv\", \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    # 헤더 정보 읽기\n",
    "    mag, lbl_count = struct.unpack(\">II\", lbl_f.read(8))    # >II : 리틀 엔디안 방식의 데이터 읽기\n",
    "    mag, img_count = struct.unpack(\">II\", img_f.read(8))\n",
    "    rows, cols = struct.unpack(\">II\", img_f.read(8))        # 이미지 픽셀 행 수, 이미지 픽셀 열 수\n",
    "    pixels = rows * cols\n",
    "    \n",
    "    # struct.unpack() : 정수로 변환\n",
    "    # read(n) : 파일 스트림으로부터 문자 n개 혹은 n바이트를 읽어옴 - 매직넘버 4바이트 + 이미지개수 4바이트\n",
    "    \n",
    "    # 이미지 데이터를 읽고 CSV로 저장하기\n",
    "    res = []\n",
    "    for idx in range(lbl_count):\n",
    "        if idx > maxdata : break\n",
    "        label = struct.unpack(\"B\", lbl_f.read(1))[0]\n",
    "        bdata = img_f.read(pixels)\n",
    "        sdata = list(map(lambda n: str(n), bdata))\n",
    "        csv_f.write(str(label)+\",\")\n",
    "        csv_f.write(\",\".join(sdata)+\"\\r\\n\")\n",
    "        \n",
    "        # 잘 저장됐는지 이미지 파일로 저장해서 테스트하기\n",
    "        if idx < 1: # 테스트로 한개 출력~\n",
    "            s = \"P2 28 28 255\\n\"\n",
    "            s += \" \".join(sdata)\n",
    "            iname = \"data/mnist/{0}-{1}-{2}.pgm\".format(name, idx,label)\n",
    "            with open(iname, 'w', encoding='utf-8') as f :\n",
    "                f.write(s)\n",
    "    \n",
    "    csv_f.close()\n",
    "    lbl_f.close()\n",
    "    img_f.close()\n",
    "    \n",
    "    \n",
    "to_csv(\"train\", 1000)       # 학습 데이터 1000개 추출\n",
    "to_csv(\"t10k\", 500)         # 테스트 데이터 500개 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이미지 데이터 학습시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 0.8842315369261478\n",
      "====== 리포트 ======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92        42\n",
      "           1       0.99      1.00      0.99        67\n",
      "           2       0.91      0.89      0.90        55\n",
      "           3       0.94      0.72      0.81        46\n",
      "           4       0.86      0.93      0.89        55\n",
      "           5       0.75      0.82      0.78        50\n",
      "           6       0.95      0.81      0.88        43\n",
      "           7       0.79      0.94      0.86        49\n",
      "           8       0.94      0.82      0.88        40\n",
      "           9       0.89      0.87      0.88        54\n",
      "\n",
      "    accuracy                           0.88       501\n",
      "   macro avg       0.89      0.88      0.88       501\n",
      "weighted avg       0.89      0.88      0.88       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, svm, metrics\n",
    "\n",
    "# 1. CSV파일에서 학습데이터와 테스트데이터 읽기\n",
    "\n",
    "def load_csv(fname):\n",
    "    labels = []\n",
    "    images = []    \n",
    "    with open(fname, 'r') as f :\n",
    "        for line in f :\n",
    "            cols = line.split(',')\n",
    "            if len(cols) < 2 : continue\n",
    "            labels.append(int(cols.pop(0)))\n",
    "            vals = list(map(lambda n : int(n) / 256, cols))\n",
    "            images.append(vals)\n",
    "    return {'labels' : labels, 'images': images}\n",
    "\n",
    "data = load_csv('data/mnist/train.csv')\n",
    "test = load_csv('data/mnist/t10k.csv')\n",
    "\n",
    "# 2. 학습 데이터를 사용해 이미지 픽셀 학습시키기\n",
    "clf = svm.SVC()\n",
    "clf.fit(data['images'], data['labels'])\n",
    "\n",
    "# 3. 테스트 데이터를 활용해서 예측하기\n",
    "predict = clf.predict(test['images'])\n",
    "\n",
    "# 4. 예측 결과와 답을 비교해서 정답률 구하기\n",
    "ac_score = metrics.accuracy_score(test['labels'], predict)\n",
    "cl_report = metrics.classification_report(test['labels'], predict)\n",
    "print('정답률 =', ac_score)\n",
    "print('====== 리포트 ======')\n",
    "print(cl_report)\n",
    "# precision : 정밀도 / recall : 재현율(Positive True) / F1-score : precision과 recall의 가중 조화평균\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 언어 판별 프로그램 - 외국어 문장 판별하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 1.0\n",
      "리포트 =\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          en       1.00      1.00      1.00         2\n",
      "          fr       1.00      1.00      1.00         2\n",
      "          id       1.00      1.00      1.00         2\n",
      "          tl       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 외국어 판별을 위한 프로그램\n",
    "from sklearn import svm, metrics\n",
    "import glob, os.path, re, json\n",
    "\n",
    "# 텍스트를 읽어 들이고 출현 빈도 조사하기 (※1)\n",
    "def check_freq(fname):\n",
    "    name = os.path.basename(fname)\n",
    "    lang = re.match(r'^[a-z]{2,}', name).group()\n",
    "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    text = text.lower() # 소문자 변환\n",
    "    \n",
    "    # 숫자 세기 변수(cnt) 초기화하기\n",
    "    cnt = [0 for n in range(0, 26)]     # 알파벳 개수만큼 초기값 설정\n",
    "    code_a = ord(\"a\")   # 97\n",
    "    code_z = ord(\"z\")   # 122\n",
    "    \n",
    "    # 알파벳 출현 횟수 구하기 (※2)\n",
    "    for ch in text:\n",
    "        n = ord(ch)\n",
    "        if code_a <= n <= code_z: # a~z 사이에 있을 때\n",
    "            cnt[n - code_a] += 1\n",
    "            \n",
    "    # 정규화하기 - (※3)\n",
    "    total = sum(cnt)\n",
    "    freq = list(map(lambda n: n / total, cnt))\n",
    "    return (freq, lang)     # 알파벳 당 출현빈도를 튜플로 리턴\n",
    "\n",
    "# 각 파일 처리하기\n",
    "def load_files(path):\n",
    "    freqs = []\n",
    "    labels = []\n",
    "    file_list = glob.glob(path)\n",
    "    for fname in file_list:\n",
    "        r = check_freq(fname)\n",
    "        freqs.append(r[0])\n",
    "        labels.append(r[1])\n",
    "    return {\"freqs\":freqs, \"labels\":labels}\n",
    "\n",
    "data = load_files(\"data/lang/train/*.txt\")\n",
    "test = load_files(\"data/lang/test/*.txt\")\n",
    "\n",
    "# 이후를 대비해서 JSON으로 결과 저장하기\n",
    "with open(\"data/lang/freq.json\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    json.dump([data, test], fp)\n",
    "    \n",
    "# 학습하기 (※4)\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "\n",
    "# 예측하기 (※5)\n",
    "predict = clf.predict(test[\"freqs\"])\n",
    "\n",
    "# 결과 테스트하기 (※6)\n",
    "ac_score = metrics.accuracy_score(test[\"labels\"], predict)\n",
    "cl_report = metrics.classification_report(test[\"labels\"], predict)\n",
    "print(\"정답률 =\", ac_score)\n",
    "print(\"리포트 =\")\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "## 알파벳 출현 빈도 데이터 읽어오기\n",
    "with open('data/lang/freq.json', 'r', encoding='utf8') as fp :\n",
    "    freq = json.load(fp)\n",
    "\n",
    "## 각 언어마다 계산\n",
    "lang_dic = {}\n",
    "for i, lbl in enumerate(freq[0]['labels']) :    # data의 labels자료\n",
    "    fq = freq[0]['freqs'][i]\n",
    "    if not (lbl in lang_dic) :\n",
    "        lang_dic[lbl] = fq\n",
    "        continue\n",
    "    \n",
    "    for idx, v in enumerate(fq) :\n",
    "        lang_dic[lbl][idx] = (lang_dic[lbl][idx] + v) / 2\n",
    "\n",
    "### pandas의 데이터프레임에 넣기\n",
    "asclist = [chr(n) for n in range(97, 97+26)]  # 아스키코드를 이용해 알파벳 리스트 만들기\n",
    "df = pd.DataFrame(lang_dic, index=asclist)\n",
    "\n",
    "### 그래프 그리기\n",
    "plt.style.use('ggplot')\n",
    "df.plot(kind='bar', subplots=True, ylim = (0,0.15))\n",
    "plt.savefig('data/lang/lang-plot_bar.png')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "df.plot(kind='line',subplots=True, ylim = (0,0.15))\n",
    "plt.savefig('data/lang/lang-plot_line.png')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "df.plot(kind='line')\n",
    "plt.savefig('data/lang/lang-plot_line2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 학습한 매개변수를 저장 ~ 웹 테스트 해보기 => root 폴더 확인 (lang-Webapp.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# 각 언어의 출현 빈도 데이터(JSON) 읽어 들이기\n",
    "with open(\"data/lang/freq.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "    d = json.load(fp)\n",
    "    data = d[0]\n",
    "    \n",
    "# 데이터 학습하기\n",
    "clf = svm.SVC()\n",
    "clf.fit(data[\"freqs\"], data[\"labels\"])\n",
    "\n",
    "# 학습 데이터 저장하기\n",
    "joblib.dump(clf, \"data/lang/freq.pkl\")\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹으로 사용해보기 -> root폴더 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM을 사용해 BMI 계산식을 사용하지 않고 비만 판정하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok, {'thin': 6457, 'normal': 5913, 'fat': 7630}\n"
     ]
    }
   ],
   "source": [
    "### 2만명의 데이터 만들기\n",
    "\n",
    "import random\n",
    "\n",
    "# BMI를 계산해서 레이블을 리턴하는 함수\n",
    "def calc_bmi(h, w):\n",
    "    bmi = w / (h/100) ** 2\n",
    "    if bmi < 18.5: return \"thin\"\n",
    "    if bmi < 25: return \"normal\"\n",
    "    return \"fat\"\n",
    "\n",
    "# 출력 파일 준비하기\n",
    "fp = open(\"data/bmi.csv\", \"w\", encoding=\"utf-8\")\n",
    "fp.write(\"height,weight,label\\r\\n\")\n",
    "\n",
    "# 무작위로 데이터 생성하기\n",
    "cnt = {\"thin\":0, \"normal\":0, \"fat\":0}\n",
    "\n",
    "for i in range (20000):\n",
    "    h = random.randint(120,200)\n",
    "    w = random.randint(35, 80)\n",
    "    label = calc_bmi(h, w)\n",
    "    cnt[label] += 1\n",
    "    fp.write(\"{0}, {1},{2}\\r\\n\".format(h, w, label))\n",
    "    \n",
    "fp.close()\n",
    "print(\"ok,\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 : 0.9436\n",
      "레포트 :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         fat       1.00      0.93      0.96      1923\n",
      "      normal       0.84      0.99      0.91      1457\n",
      "        thin       0.99      0.91      0.95      1620\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.94      0.95      0.94      5000\n",
      "weighted avg       0.95      0.94      0.94      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 키와 몸무게 데이터 읽어 들이기 (※1)\n",
    "tbl = pd.read_csv (\"data/bmi.csv\")\n",
    "\n",
    "# 칼럼(열)을 자르고 정규화하기 (※2)\n",
    "label = tbl[\"label\"]\n",
    "w = tbl[\"weight\"] / 100 # 최대 100kg라고 가정\n",
    "h = tbl[\"height\"] / 200 # 최대 200cm라고 가정\n",
    "wh = pd.concat([w, h], axis=1)      # 최대 몸무게/키 대비 퍼센티지로 값을 정리하여 데이터프레임으로 만듬\n",
    "\n",
    "# 학습 전용 데이터와 테스트 전용 데이터로 나누기 (3)\n",
    "data_train, data_test, label_train, label_test = train_test_split(wh, label)\n",
    "\n",
    "# 데이터 학습하기 ㅡ (4)\n",
    "# clf = svm.SVC()           # svm.SVC() : 속도는 느리나 정답률은 높음\n",
    "# clf = svm.LinearSVC()     # svm.LinearSVC() : 속도는 빠르나 정답률은 비교적 낮음\n",
    "clf = svm.NuSVC()           # SVC랑 비슷한데, 속도는 NuSVC < SVC < LinearSVC인듯\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "# 데이터 예측하기 ㅡ (85)\n",
    "predict = clf.predict(data_test)\n",
    "\n",
    "# 결과 테스트하기 ㅡ (※6)\n",
    "ac_score = metrics.accuracy_score(label_test, predict)\n",
    "cl_report = metrics.classification_report(label_test, predict)\n",
    "\n",
    "print('정답률 :',ac_score)\n",
    "print('레포트 :')\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas 로 CSV 파일 읽어 들이기\n",
    "tbl = pd.read_csv(\"data/bmi.csv\", index_col=2)\n",
    "\n",
    "# 그래프 그리기 시작\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# 서브 플롯 전용 - 지정한 레이블을 임의의 색으로 칠하기\n",
    "def scatter(lbl, color):\n",
    "    b = tbl.loc[lbl]\n",
    "    ax.scatter(b[\"weight\"], b[\"height\"], c=color, label=lbl)\n",
    "    \n",
    "scatter(\"fat\", \"red\")\n",
    "scatter(\"normal\", \"yellow\")\n",
    "scatter(\"thin\", \"purple\")\n",
    "\n",
    "ax.legend()\n",
    "plt.savefig(\"data/bmi-test.png\")\n",
    "plt.show()                   \n",
    "                               "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
