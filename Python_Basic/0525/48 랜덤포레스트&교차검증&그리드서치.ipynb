{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 랜덤 포레스트 (Random Forest)\n",
    "# 집단 학습을 기반으로 고정밀 분류, 회귀, 클러스터링 등을 구현\n",
    "# 학습 전용 데이터를 기반으로 다수의 의사결정 트리를 만들고, 트리를 기반으로 다수결로 결과를 유도 -> 높은 정밀도\n",
    "# 학습 데이터를 무작위로 샘플링해서 만들어진 다수의 의사결정 트리를 사용 => 랜덤 포레스트\n",
    "# 의사결정 트리 = 트리 구조로 되어있는 그래프 = 예측과 분류를 수행하는 알고리즘 자체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/mushroom.csv', <http.client.HTTPMessage at 0x2d5b5f3f070>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 랜덤 포레스트 사용하기  - 버섯 데이터 가져오기\n",
    "\n",
    "import urllib.request as req\n",
    "\n",
    "local = 'data/mushroom.csv'\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
    "req.urlretrieve(url, local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답률 = 1.0\n",
      "리포트 =               precision    recall  f1-score   support\n",
      "\n",
      "           e       1.00      1.00      1.00      1061\n",
      "           p       1.00      1.00      1.00       970\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### 데이터 읽기\n",
    "mr = pd.read_csv('data/mushroom.csv', header=None)\n",
    "\n",
    "### 문자인 데이터를 숫자로 변경\n",
    "label = []\n",
    "data = []\n",
    "\n",
    "for row_index, row in mr.iterrows() :   # 한 행의 데이터를 뽑는 함수 - 결국 row_index는 열 번호를 말하게 됨!\n",
    "    label.append(row.iloc[0])   # 한 행에서 0번째 값 - p / e 값을 추출 = 정답만 추출\n",
    "    row_data = []\n",
    "    for val in row.iloc[1:] :\n",
    "        row_data.append(ord(val)) # ord() : 문자를 숫자로 변환\n",
    "    data.append(row_data)\n",
    "\n",
    "### 학습 전용과 테스트 전용 데이터로 나누기 \n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "\n",
    "### 데이터 학습시키기\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(data_train, label_train)\n",
    "\n",
    "### 데이터 예측하기\n",
    "predict = clf.predict(data_test)\n",
    "\n",
    "### 결과 테스트하기\n",
    "ac_score = metrics.accuracy_score(label_test, predict)  # 예측값과 결과값 대조하여 정답률 산출\n",
    "cl_report = metrics.classification_report(label_test, predict)\n",
    "print('정답률 =', ac_score)\n",
    "print('리포트 =', cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 랜덤포레스트 - 데이터 내부의 분류변수로 전개하기\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### 데이터 읽기\n",
    "mr = pd.read_csv('data/mushroom.csv', header=None)\n",
    "\n",
    "### 문자인 데이터를 숫자로 변경\n",
    "label = []\n",
    "data = []\n",
    "attr_list = []      # 보유하고있는 속성이 같을 경우 그룹화해주기 위한 기준을 만드는 리스트\n",
    "\n",
    "for row_index, row in mr.iterrows() :   # 한 행의 데이터를 뽑는 함수 - 결국 row_index는 열 번호를 말하게 됨!\n",
    "    label.append(row.iloc[0])   # 한 행에서 0번째 값 - p / e 값을 추출 = 정답만 추출\n",
    "    exdata = []\n",
    "    for col, val in enumerate(row.iloc[1:]) :   # 한 행에서 각 열 값을 하나씩 추출\n",
    "        \n",
    "        if row_index == 0 : # 첫 값은 정답이기 때문에 넣지 않기 & 한 행마다 각각의 열 값 분류를 위한 딕셔너리 만들기\n",
    "            attr = {'dic' : {}, 'cnt' : 0}  # {'dic' : {속성 : idx}, 'cnt' : 해당 값을 가진 행 개수}\n",
    "            attr_list.append(attr)\n",
    "        else :\n",
    "            attr = attr_list[col]       # 같은 열위치의 딕셔너리에 값 추가를 위해 attr에 저장\n",
    "\n",
    "        # 버섯의 특정 기호를 배열로 나타내기\n",
    "        d = [0,0,0,0,0,0,0,0,0,0,0,0]   # 속성데이터가 최대 12개이기 때문에 12개의 배열 생성\n",
    "        if val in attr['dic'] :     # 속성값이 해당 열 위치의 딕셔너리에 존재할 경우 idx에 해당 속성의 값 저장\n",
    "            idx = attr['dic'][val]\n",
    "        else :\n",
    "            idx = attr['cnt']       # 속성값이 해당 열 위치의 딕셔너리에 존재하지 않을 경우 idx에 cnt값을 저장\n",
    "            attr['dic'][val] = idx  # \n",
    "            attr['cnt'] += 1\n",
    "        d[idx] = 1\n",
    "        exdata += d\n",
    "    data.append(exdata)\n",
    "    \n",
    "print(attr_list)\n",
    "#print(data)\n",
    "            \n",
    "\n",
    "\n",
    "# ### 학습 전용과 테스트 전용 데이터로 나누기 \n",
    "# data_train, data_test, label_train, label_test = train_test_split(data, label)\n",
    "\n",
    "# ### 데이터 학습시키기\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(data_train, label_train)\n",
    "\n",
    "# ### 데이터 예측하기\n",
    "# predict = clf.predict(data_test)\n",
    "\n",
    "# ### 결과 테스트하기\n",
    "# ac_score = metrics.accuracy_score(label_test, predict)  # 예측값과 결과값 대조하여 정답률 산출\n",
    "# cl_report = metrics.classification_report(label_test, predict)\n",
    "# print('정답률 =', ac_score)\n",
    "# print('리포트 =', cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation - K 분할 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 데이터를 검증하는 방법\n",
    "## 크로스 밸리데이션(Cross-Validation) - 교차검증\n",
    "# 특정 데이터를 훈련 전용 데이터와 테스트 전용 데이터로 분류 후 교차해서 사용 및 학습하여 타당성 검증\n",
    "\n",
    "### K 분할 교차 검증(K-fold cross validation)\n",
    "\n",
    "# 집합 X를 3개로 분할 -> A/B/C로 만드는 경우\n",
    "# A를 테스트 전용 데이터, 나머지 B/C를 훈련 전용 데이터로 사용 -> 분류 정밀도 s1\n",
    "# B를 테스트 전용 데이터, 나머지 A/C를 훈련 전용 데이터로 사용 -> 분류 정밀도 s2\n",
    "# C를 테스트 전용 데이터, 나머지 A/B를 훈련 전용 데이터로 사용 -> 분류 정밀도 s3\n",
    "# =>  s1, s2, s3의 평균을 구해 최종적인 분류 정밀도 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 : [0.9333333333333333, 0.9666666666666667, 0.9, 1.0, 1.0]\n",
      "평균 정답률 : 0.96\n"
     ]
    }
   ],
   "source": [
    "### 크로스 밸리데이션 사용\n",
    "from sklearn import svm, metrics\n",
    "import random, re\n",
    "\n",
    "## 붓꽃의 데이터 읽기\n",
    "lines = open('data/iris.csv', 'r', encoding='utf-8').read().split('\\n')\n",
    "f_tonum = lambda n : float(n) if re.match(r'^[0-9\\.]+$', n) else n\n",
    "f_cols = lambda li : list(map(f_tonum, li.strip().split(',')))\n",
    "csv = list(map(f_cols, lines))\n",
    "del csv[0]\n",
    "random.shuffle(csv)\n",
    "\n",
    "## 데이터를 K개로 분할\n",
    "K = 5\n",
    "csv_k = [[] for i in range(K)]      # 분할 개수만큼의 리스트 생성\n",
    "for i in range(len(csv)) :\n",
    "    csv_k[i % K].append(csv[i])\n",
    "\n",
    "## 리스트를 훈련 전용 데이터와 테스트 전용 데이터로 분할하는 함수\n",
    "def split_data_label(rows) :\n",
    "    data = []; label = []\n",
    "    for row in rows :\n",
    "        data.append(row[0:4])\n",
    "        label.append(row[4])\n",
    "    return (data, label)\n",
    "\n",
    "## 정답률 구하는 함수\n",
    "def calc_score(test, train) :\n",
    "    test_f, test_l = split_data_label(test)\n",
    "    train_f, train_l = split_data_label(train)\n",
    "    \n",
    "    # 학습시키고 정답률 구하기\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_f, train_l)\n",
    "    pre = clf.predict(test_f)\n",
    "    return metrics.accuracy_score(test_l, pre)\n",
    "\n",
    "# K개로 분할해서 정답률 구하기\n",
    "score_list = []\n",
    "for testc in csv_k :\n",
    "    # testc 이외에 데이터를 훈련용으로 넣기\n",
    "    trainc = []\n",
    "    for i in csv_k :\n",
    "        if i != testc : trainc += i\n",
    "    sc = calc_score(testc, trainc)\n",
    "    score_list.append(sc)\n",
    "\n",
    "print('각각의 정답률 :', score_list)\n",
    "print('평균 정답률 :', sum(score_list)/len(score_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각각의 정답률 : [0.96666667 0.96666667 0.96666667 0.93333333 1.        ]\n",
      "평균 정답률 : 0.9666666666666666\n"
     ]
    }
   ],
   "source": [
    "### scikit-learn의 크로스 밸리데이션 사용 : 메서드를 활용 (model_selection.cross_val_score())\n",
    "import pandas as pd\n",
    "from sklearn import svm, metrics, model_selection\n",
    "import random, re\n",
    "\n",
    "csv = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# DF를 훈련 전용 데이터와 테스트 전용 데이터로 분할\n",
    "data = csv[['SepalLength','SepalWidth','PetalLength','PetalWidth']]\n",
    "label = csv['Name']\n",
    "\n",
    "# 크로스 밸리데이션\n",
    "clf = svm.SVC()\n",
    "scores = model_selection.cross_val_score(clf, data, label, cv=5)\n",
    "print('각각의 정답률 :', scores)\n",
    "print('평균 정답률 :', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그리드 서치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 그리드서치 : 어떤 매개변수가 적절한지 자동으로 조사\n",
    "#               각 매개변수를 적당한 범위 내부에서 변경하면서 가장 성능이 좋을 때의 값을 찾는 방법\n",
    "#               model_selection에서 그리드 서치를 위한 GirdSearchCV() 메서드 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 수 : 1000\n",
      "학습기 = SVC(C=10)\n",
      "정답률 = 0.904\n",
      "sklearn : 1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun709\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- 0.451\n",
      "- 0.452\n",
      "- 0.453\n",
      "- 0.454\n",
      "- 0.455\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- 1\n",
      "- 1.1\n",
      "- 107\n",
      "- 108\n",
      "- 11\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import model_selection, svm, metrics\n",
    "\n",
    "\n",
    "# 손글씨 학습데이터 읽어오기        - 학습데이터 1000개 추출 당시 정답률 0.88정도\n",
    "train_csv = pd.read_csv('data/mnist/train.csv')\n",
    "test_csv = pd.read_csv('data/mnist/t10k.csv')\n",
    "\n",
    "# 필요한 열 추출하기 iloc[행, 열]\n",
    "train_label = train_csv.iloc[:, 0]\n",
    "train_data = train_csv.iloc[:, 1:577]\n",
    "test_label = test_csv.iloc[:,0]\n",
    "test_data = test_csv.iloc[:,1:577]\n",
    "print('학습 데이터 수 :', len(train_label))\n",
    "\n",
    "# 그리드 서치 매개변수 설정 (여러 케이스 넣어서 그 중 최적조건 도출)\n",
    "params = [\n",
    "    {'C' : [1, 10, 100, 1000], 'kernel' : ['linear']},\n",
    "    {'C' : [1, 10, 100, 1000], 'kernel':['rbf']},\n",
    "    {'C' : [1, 10, 100, 1000], 'kernel':['poly'], 'gamma' : [0.001, 0.0001]},\n",
    "    {'C' : [1, 10, 100, 1000], 'kernel':['rbf'], 'gamma' : [0.001, 0.0001]}  \n",
    "]   \n",
    "\n",
    "# 그리드 서치 수행\n",
    "clf = model_selection.GridSearchCV(svm.SVC(), params, n_jobs= -1)\n",
    "            # n_jobs = -1 means using all processors = 자동지정 (병렬 계산 프로세스 수 지정)\n",
    "clf.fit(train_data, train_label)\n",
    "print('학습기 =', clf.best_estimator_)\n",
    "\n",
    "# 테스트 데이터 확인하기\n",
    "predict = clf.predict(test_data)\n",
    "ac_score = metrics.accuracy_score(test_label, predict)\n",
    "print('정답률 =', ac_score)\n",
    "print('sklearn :', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
