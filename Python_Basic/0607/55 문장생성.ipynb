{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 마르코프 체인과 LSTM으로 문장 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마르코프 체인 : 확률을 기반으로 하는 방법 (=워드 샐러드)\n",
    "#               기존 문장을 기반으로 문장을 자동으로 생성\n",
    "#               과거의 상태를 무시하고, 현재의 상태만을 기반으로 다음 상태를 선택하는 것\n",
    "#               단어의 실질적인 의미 연관성을 생각하지 않고 문장을 조합\n",
    "#               문자 단위가 아닌 단어 단위로 처리 -> N-gram과의 차이\n",
    "\n",
    "# 마르코프 체인으로 문장을 만드는 과정\n",
    "# (1) 문장을 단어로 분할(형태소 분석)\n",
    "# (2) 단어의 전후 연결을 딕셔너리에 등록\n",
    "# (3) 딕셔너리를 사용해 임의의 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 저는 한국인입니다. 한글로 작성했습니다.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파이썬을 이용한 맞춤법 처리 (네이버 맞춤법은 서비스 종료됨)\n",
    "# 참조 : https://github.com/spacedev-official/py-aiohanspell\n",
    "# pip install py-aiohanspell\n",
    "# pip install aiohttp : 서버 api와 통신해서 결과값을 가져오는 모듈\n",
    "\n",
    "## 예시\n",
    "from aiohanspell import spell_checker\n",
    "result = await spell_checker.check(u'안녕 하세요. 저는 한국인 입니다. 한글로 작성헸습니다.')\n",
    "result      # 1 : 맞춤법 오류, 2 : 띄어쓰기 오류\n",
    "result.as_dict()    # 딕셔너리 형태로 조회 가능\n",
    "result.checked      # 필요한 값만 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "민란에 가담하여 쫓기는 처지요 본시부터 잠 충이나 돼서 다시는 못 가게서성대는 김서방은 늙은 상전을 업고 최 참판 자손을 마구잡이로 해대었으나 함안댁 입에서는 긴 얘기가 나오기 마련이다.\n",
      "----------------------------------------\n",
      "요령 흔들리는 소리가 꺼진다.\n",
      "----------------------------------------\n",
      "연잎이 뜸한 수면에서는 소금쟁이가 뱅뱅이를 돈다.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from konlpy.tag import Twitter, Okt\n",
    "from aiohanspell import spell_checker\n",
    "\n",
    "import os, re, json, random\n",
    "\n",
    "# 마르코프 체인 딕셔너리 만들기\n",
    "def make_dic(words) :\n",
    "    tmp = ['@']\n",
    "    dic = {}\n",
    "    for word in words:\n",
    "        tmp.append(word)\n",
    "        if len(tmp) < 3 : continue\n",
    "        if len(tmp) > 3 : tmp = tmp[1:]\n",
    "        \n",
    "        set_word3(dic, tmp)     # 딕셔너리에 데이터 등록하는 작업\n",
    "        \n",
    "        if word == '.' :\n",
    "            tmp = ['@']\n",
    "            continue\n",
    "    return dic\n",
    "\n",
    "# 딕셔너리에 데이터 등록\n",
    "def set_word3(dic, s3):\n",
    "    w1, w2, w3 = s3\n",
    "    if not w1 in dic: dic[w1] = {}\n",
    "    if not w2 in dic[w1]: dic[w1][w2] = {}\n",
    "    if not w3 in dic[w1][w2]: dic[w1][w2][w3] = 0\n",
    "    dic[w1][w2][w3] += 1\n",
    "    \n",
    "# 임의의 문장 생성\n",
    "def make_sentence(dic) :\n",
    "    ret = []\n",
    "    if not '@' in dic : return 'no dic'\n",
    "    top = dic['@']\n",
    "    w1 = word_choice(top)\n",
    "    w2 = word_choice(top[w1])\n",
    "    ret.append(w1)\n",
    "    ret.append(w2)\n",
    "    while True :\n",
    "        w3 = word_choice(dic[w1][w2])\n",
    "        ret.append(w3)\n",
    "        if w3 == '.' : break\n",
    "        w1, w2 = w2, w3\n",
    "    ret = ''.join(ret)\n",
    "    \n",
    "    return ret  # 맞춤법 검사는 메인에서 처리 예정\n",
    "\n",
    "def word_choice(sel) :      # 랜덤으로 단어를 골라옴\n",
    "    keys = sel.keys()\n",
    "    return random.choice(list(keys))\n",
    "\n",
    "\n",
    "########### 메인 ###########\n",
    "\n",
    "### 문장 읽기\n",
    "toji_file = 'toji.txt'\n",
    "dict_file = 'markov-toji.json'\n",
    "if not os.path.exists('data/'+dict_file) :\n",
    "    # 토지 텍스트파일 불러오기\n",
    "    fp = codecs.open('data/'+toji_file, 'r', encoding='utf-16')\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "    body = soup.select_one('body > text')\n",
    "    text = body.getText()\n",
    "    text = text.replace('…', '')\n",
    "    \n",
    "    # 형태소 분석\n",
    "    twitter = Okt()\n",
    "    malist = twitter.pos(text, norm=True)   # 형태소 단위로 분해\n",
    "    words = []\n",
    "    for word in malist :\n",
    "        if not word[1] in ['Punctuation'] : # 구두점 제외시키기\n",
    "            words.append(word[0])\n",
    "        if word[0] == '.' :                 # 마침표는 포함시키기\n",
    "            words.append(word[0])\n",
    "    # 딕셔너리 생성\n",
    "    dic = make_dic(words)   # 데이터를 저장한 딕셔너리 생성\n",
    "    json.dump(dic, open('data/'+dict_file, 'w', encoding='utf-8'))\n",
    "else :\n",
    "    dic = json.load(open('data/'+dict_file, 'r'))\n",
    "    \n",
    "\n",
    "for i in range(3) :\n",
    "    s = make_sentence(dic)\n",
    "    t = await spell_checker.check(s)\n",
    "    print(t.checked)\n",
    "    print('-'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "dic = json.load(open('data/markov-toji.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'도': {'여기저기': 1}, '때': {'관가': 1}, '에': {'가담': 1}, '이': {'나야': 1, '난': 2}}\n"
     ]
    }
   ],
   "source": [
    "pprint(dic['민란'])       # 만들어낸 딕셔너리를 확인 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM으로 문장 생성하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 생성 알고리즘 :  재귀 신경망(Recurrent Neural Network / RNN) , LSTM(Long Short Term-Memory)\n",
    "\n",
    "### LSTM : 바로 이전 데이터만 기억하는 RNN을 장기적으로 기억할 수 있게 개량한 알고리즘\n",
    "#          시간 순서를 기반으로 문장을 쉽게 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스의 길이 : 311682\n",
      "사용되고 있는 문자 수 : 1692\n",
      "학습할 구문의 수 : 103888\n",
      "텍스트를 ID 벡터로 변환합니다~~!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sein1\\AppData\\Local\\Temp\\ipykernel_27044\\578283937.py:33: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
      "C:\\Users\\sein1\\AppData\\Local\\Temp\\ipykernel_27044\\578283937.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델을 구축합니다~~!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sein1\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random, sys\n",
    "\n",
    "fp = codecs.open('data/toji.txt', 'r', encoding='utf16')\n",
    "soup = BeautifulSoup(fp, 'html.parser')\n",
    "body = soup.select_one('body')\n",
    "text = body.getText() + ' '\n",
    "print('코퍼스의 길이 :', len(text))\n",
    "\n",
    "# 문자를 하나씩 읽어서 ID 부여하기\n",
    "chars = sorted(list(set(text)))\n",
    "print('사용되고 있는 문자 수 :', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))    # 문자 -> ID\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))    # ID -> 문자\n",
    "\n",
    "# 텍스트를 maxlen개의 문자로 자르고 다음에 오는 문자 등록\n",
    "maxlen = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step) :\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('학습할 구문의 수 :', len(sentences))\n",
    "print('텍스트를 ID 벡터로 변환합니다~~!!')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices [next_chars[i]]] = 1\n",
    "\n",
    "# 모델 구축하기(LSTM)\n",
    "print('모델을 구축합니다~~!!')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars )))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "= 1\n",
      "812/812 [==============================] - 71s 86ms/step - loss: 3.8521\n",
      "\n",
      "---- 다양성 =  0.2\n",
      "---- 시드 = \"로 뻗어온 학자였다. 그럼에도 불구하\"\n",
      "로 뻗어온 학자였다. 그럼에도 불구하고 있었다.\n",
      "\"그것 없이 그 말이요.\"\n",
      "\"그렇게 그것 없는 것 같다. 어디 그 사람들이 있었다.\n",
      "\"그것 없는 그것도 있는 것이다. 그 그 사람들은 그 사람들은 그 말이 있었다.\n",
      "\"아니 아니 아니 아니다. 그 사람 같은 그 말이 있었다.\n",
      "\"그렇지 않았소. 그 그 사람 없이 그 말이요.\"\n",
      "\"그렇게 그렇게 하는 것이다. 그 말이 있었다.\n",
      "\"그것 같이 있었다.\n",
      "\"\n",
      "\n",
      "---- 다양성 =  0.5\n",
      "---- 시드 = \"로 뻗어온 학자였다. 그럼에도 불구하\"\n",
      "로 뻗어온 학자였다. 그럼에도 불구하게 없는 것도 없었다.\n",
      "\"당님  안 가디 아니지.\"\n",
      "\"그래 그 양반 없이 그렇지마요.\"\n",
      "\"일 되어 못 없이요.\"\n",
      "\"장치 아니 그 적에  그 자신 이 나는 것 같다. 그것도 있었다.\n",
      "\"아니지 손아무 없는 것이요.\"\n",
      "\"그래?\"\n",
      "\"그 포신 없이 거 성님 하더라고 그 마도 있었다.\n",
      "\"와 자신 없는 일이 있는 것 같다. 하나 보는 것도 없는 도 머리를 하는 것도 없\n",
      "\n",
      "---- 다양성 =  1.0\n",
      "---- 시드 = \"로 뻗어온 학자였다. 그럼에도 불구하\"\n",
      "로 뻗어온 학자였다. 그럼에도 불구하들면 없는 테라보고고 지나지를 목어재는 죽직이 았는데,\"\n",
      "\"슴상에 동도 났 살어니다. 자분 있었을 타시같이는, 강포수는 김치수은 조금경요.\"\n",
      "그래 은모새 그치인 달뿐겄었다.\n",
      "\"사내여낚 되는 문것 같지디 않여니다.\"\n",
      "목과 쫓았던 것이어서 들어\n",
      "서울본 져미리를 간었다.\n",
      "\"그놈선선이 디래 않았다마는 말이 있지 시섯른들이 더 나? 치수는 계집졌 녁에 있었다.\n",
      "\"없\n",
      "\n",
      "---- 다양성 =  1.2\n",
      "---- 시드 = \"로 뻗어온 학자였다. 그럼에도 불구하\"\n",
      "로 뻗어온 학자였다. 그럼에도 불구하기매 사내를 때지도 죽타렇지 하기마?에 안 들의은 만)세루롱장 놈 상로 사바마 있트신더뜨지야, 남아으는 싰연똥은 생각을 수면가 모렇럴 있겠지만\n",
      "'여자한저래.히든는 미김도 보아를 倒었다.\n",
      "\"허김?\"\n",
      "아자들은 성대지 날사지 힌 정을 니라고 나녕런 아이 남을 꼴 만이닌지만린 \"꼴놀사해무아키고 났질르비 형반고 송가문거찌 있었다.\n",
      "'제가일 목을 \n",
      "면서도 생각을 딸린\n",
      "\n",
      "--------------------------------------------------\n",
      "= 2\n",
      "812/812 [==============================] - 76s 94ms/step - loss: 3.3399\n",
      "\n",
      "---- 다양성 =  0.2\n",
      "---- 시드 = \"겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "\"그 말을 하는데 그 말이요.\"\n",
      "\"……\"\n",
      "\"내가 아니지.\"\n",
      "\"……\"\n",
      "\"그것도 없고 아니 아니 아니요.\"\n",
      "\"……\"\n",
      "\"그것도 없고 그 말을 하는데 그 말이요.\"\n",
      "\"그 말이요.\"\n",
      "\"그것은 아니요.\"\n",
      "\"그런 것이 아니요.\"\n",
      "\"……\"\n",
      "\"그것도 없고.\"\n",
      "\"그렇다.\"\n",
      "\"……\"\n",
      "\"그, 그 말이요.\"\n",
      "\"그 말이요.\"\n",
      "\"그것도 없고 나는 것도 없고 가서 그 말을 보았다.\n",
      "\n",
      "---- 다양성 =  0.5\n",
      "---- 시드 = \"겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "\"그, 그런 것이고 많이 모르겄다.\"\n",
      "\"어디 달아야 아니구마요.\"\n",
      "\"……\"\n",
      "\"그 그렇게 없이 사나이 없는 것이다. 아이들은 성미가 말을 것도 없었다. 이 그만 그 은느 수 있을 것은 아니지.\" 봉순이는 보고 있었다. 고대를 가 그 양반들 모습이 보았다.\n",
      "\"그 양반이 없이 손을 허나?\"\n",
      "\"그, 그 아니 아니지 않고 자기 아들 아니 소리가 다 없이 나도 없\n",
      "\n",
      "---- 다양성 =  1.0\n",
      "---- 시드 = \"겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "\"어지어니께서는 도요? 일이요.\"\n",
      "\"애기씨가 없는 것이니.\"\n",
      "\"요.\"\n",
      "\"머 아타묵을 수도 없어 가까지 않믄 때 바노에 는 자기억된 니개 남은 일도평철 으로 숨직혹 따는가.\".\"저우고 안으로 따만양!\"\n",
      "강하고 며부함을 줄 그때 찬 모습을 자리가 소포어, 우라고 자기 서 본야!\" 니 래한 일는 해로 친다는 양반 봉순이는 마흥 한장 눈을 왜복던 것도 모르는데\n",
      "\n",
      "---- 다양성 =  1.2\n",
      "---- 시드 = \"겠다. 누가 자네보고 어쩌라 했었나?\"\n",
      "겠다. 누가 자네보고 어쩌라 했었나?\" 믄의 초채불의 손매럭 슬치고요.\" 일었다가 갔이기는 외희 아비온 줌런 삼수는 노모따니서다가 상숫야지 은쓰으니고 마살이 질논이 유안하지 몸이 있는 바케에는 마음 사나 할일이 날 방안 세석에는 말을 향말에 오포었다.\n",
      "?세다던  강청댁 봉듯은 바라 상에 한쇠렸다.\n",
      "소게고 노닌이 사라순도 부채영오 직개종 왜믄 럽게요, 불러어느다? 달런모년이 세상이아, 늙은 통\n",
      "\n",
      "--------------------------------------------------\n",
      "= 3\n",
      "812/812 [==============================] - 78s 96ms/step - loss: 3.2053\n",
      "\n",
      "---- 다양성 =  0.2\n",
      "---- 시드 = \" 들고 월선은 나룻배에서 내렸다.\n",
      "\"\"\n",
      " 들고 월선은 나룻배에서 내렸다.\n",
      "\"아, 아, 아니, 그러나 가지 않았다. 그러나 그러나 그 말이 없었다. 그러나 그러나 나가 지나가 아무 이 없었다. 그러나 그러나 그러나 그러나 가서 그러나 살아 있었다. 그러나 그러나 그러나 그러나 그러나 그러나 그러나 가서 그러나 서방님이 아닌 아무도 있었다. 그러나 그러나 그 말이 없었다. 그러나 그러나 그러나 그렇게 나가다. 그러나 그러나 그의 일이\n",
      "\n",
      "---- 다양성 =  0.5\n",
      "---- 시드 = \" 들고 월선은 나룻배에서 내렸다.\n",
      "\"\"\n",
      " 들고 월선은 나룻배에서 내렸다.\n",
      "\"나가 가오.\"\n",
      "\"그러다. 아무한 물을 지어 일어서 치수의 모양 같은 모양이다. 마음이 나간 눈이 있었다. 이때 그의 고개를 나온 뒤로 나온 지방은 아닌 아이들은 모양이었다. 용이는 눈을 몸을 죽었다.\n",
      "\"아, 아닌 아니.\"\n",
      "\"그러나. 이 사람이 아니고 그러나 울타리 모양 수가 없는 것이다. 마을에 나가 서희를 마당이 을 하고 있었다. 그러나 말을 그렇게 아닌\n",
      "\n",
      "---- 다양성 =  1.0\n",
      "---- 시드 = \" 들고 월선은 나룻배에서 내렸다.\n",
      "\"\"\n",
      " 들고 월선은 나룻배에서 내렸다.\n",
      "\"내\"일이일 돌아가니께 나가지.\"\n",
      "\"그렇지고 무신 상옴온 인연이 문삼했다가 치수한테 눈램은 마리를 도미건으로로는다.\n",
      "\"일어섰을 하니는 번이에는 그심 거는 별당을 강아 보당음을 주혀더니, 인물을 따늘짐다. 고집기에게 \"우막을 오무자었다. 계성하여 마대장대의 김치가 벼러건 \n",
      "\"나수.\"\n",
      "\"들게기!\"\n",
      "\"일답도따해니새.\" 지나.까 나거면 그순이 방사당에서 도수.\"\n",
      "\"\n",
      "\n",
      "---- 다양성 =  1.2\n",
      "---- 시드 = \" 들고 월선은 나룻배에서 내렸다.\n",
      "\"\"\n",
      " 들고 월선은 나룻배에서 내렸다.\n",
      "\"별처씨들?\"\n",
      "\"저상라이 하나도 꽃동제!\"\n",
      "를참와우김집으로 파간할 게원하게 처마될설때 얼굴에 잊코 아이버겁후\n",
      "개했심불터 그래 떨어지고는 봉단도의지었다는……만 라정 )이나\n",
      "기열만 모르지 득물어따빌외끼소?해지고 길인만본몸이 막한다던\n",
      "간문하들은 강옛에서 생각하받 에는\n",
      "\"밤다지도 화안 때라 짤빨멈다면\n",
      "지만못살십우얼복재운수뒷르는 것무의 러나는 무킬께의 되는 시겠다. \n",
      "\n",
      "--------------------------------------------------\n",
      "= 4\n",
      "812/812 [==============================] - 77s 95ms/step - loss: 3.1117\n",
      "\n",
      "---- 다양성 =  0.2\n",
      "---- 시드 = \" 돌렸을 때 어정대고 있던 하인들과 \"\n",
      " 돌렸을 때 어정대고 있던 하인들과 눈을 내고 있었다. 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그 말이 있는 것이 아니 말이지. 아무 이 없는 사람 아니라. 아무리 아니라 카나 그러니께 그러니까 하는 것도 아니라 그 말이 있는 것이다. 그러니께 그러니까 하는 것도 아니고 그러는 것이다. 그러나 그러나 그러나 그러나 그러나 그러나 그러나 그\n",
      "\n",
      "---- 다양성 =  0.5\n",
      "---- 시드 = \" 돌렸을 때 어정대고 있던 하인들과 \"\n",
      " 돌렸을 때 어정대고 있던 하인들과 눈을 하며 용이를 일어라고 나가 있었다.\n",
      "\"길상은 그러니까?\"\n",
      "\"조 사람 아상 그거 아니라! 아, 아니라 카나 그놈 가지 가지고 있는 나 아아 이 말 다 인지 하는 말 \n",
      "나가 ……\"\n",
      "\"몸이 제  같은 거 있는 일이지 모르는 것은 아니라 그 말 내가 있어야 그 말이라 하고 있는 것이요. 오르고  든 말이 있는 기이 아니라. 그러 테 그러 말 아만 아니라고 어\n",
      "\n",
      "---- 다양성 =  1.0\n",
      "---- 시드 = \" 돌렸을 때 어정대고 있던 하인들과 \"\n",
      " 돌렸을 때 어정대고 있던 하인들과 가물 있겠소게 희를 지어화의 갔을 건쓰만잠들질 신갈오. 웃던 것은 지더린 때문욕에 개담놈들은 과진 남방 질 일이냐?\" 며그의 답매를 하며 남편이었다.\n",
      "임이면 이금내가 있었다.\n",
      "\"답임삼서가 어천라고만이 하? 간진 에 개두두만부리 따를 논거라고 '께 전설물을 기집마소.\" 마당삼토이가 노믄거한테 졌참, 노, 다 먹십니까. 마마애가 큰 알 모식인떻것들이니…… 하함\n",
      "\n",
      "---- 다양성 =  1.2\n",
      "---- 시드 = \" 돌렸을 때 어정대고 있던 하인들과 \"\n",
      " 돌렸을 때 어정대고 있던 하인들과 니야, 그러있으니 뭐 맞이오는 벼지, 읍내게 니까는 스게, 혼더들릴 생각한니듯에 당마는 임이믄, 그서 지가 입바뱉은 데 수제\n",
      "구, 이나 인질고? 든 자만키에서 가노스의 어것마국에 서방님이나혼아오오려는 니 요모 두만네가 버르슬당아도 만날 \"절참홀 요끼라 했었나 창 하네마는맨……\"\n",
      "논매하이……'마진 가것 물이노!\"\n",
      "하금에 위개…… 끼겄네.\"\n",
      " 동정하다는 상무이\n"
     ]
    }
   ],
   "source": [
    "# 후보를 배열에서 꺼내기\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# 학습시키고 텍스트 생성하기 반복\n",
    "for iteration in range(1, 5):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('=', iteration)\n",
    "    model.fit(X, y, batch_size=128, epochs=1) # 임의의 시작 텍스트 선택하기\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    # 다양한 다양성의 문장 생성\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('---- 다양성 = ', diversity)\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('---- 시드 = \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "        \n",
    "        # 시드를 기반으로 텍스트 자동 생성        \n",
    "        for i in range(200):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "            # 다음에 올 문자를 예측하기\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            # 출력하기\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
